{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading Torch Library**"
      ],
      "metadata": {
        "id": "RFOOru0wHuiJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WfO89_SDHjs3"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reshaping, Stacking, Squeezing, and Unsqueezing Tensors in PyTorch\n",
        "\n",
        "Often, you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them. This is a common requirement in deep learning workflows where tensor shapes must align with model expectations.\n",
        "\n",
        "## Popular Tensor Manipulation Methods\n",
        "\n",
        "| Method                                      | One-line Description                                                                                      |\n",
        "|---------------------------------------------|----------------------------------------------------------------------------------------------------------|\n",
        "| [torch.reshape(input, shape)](https://pytorch.org/docs/stable/generated/torch.reshape.html) | Reshapes `input` to `shape` (if compatible). Can also use `torch.Tensor.reshape()`.                        |\n",
        "| [Tensor.view(shape)](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view)          | Returns a **view** of the original tensor in a different `shape` but shares the same data as the original tensor. |\n",
        "| [torch.stack(tensors, dim=0)](https://pytorch.org/docs/stable/generated/torch.stack.html)    | Concatenates a sequence of `tensors` along a new dimension (`dim`). All tensors must be the same size.    |\n",
        "| [torch.squeeze(input)](https://pytorch.org/docs/stable/generated/torch.squeeze.html)          | Removes all dimensions of size 1 from `input`.                                                           |\n",
        "| [torch.unsqueeze(input, dim)](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html) | Returns `input` with a dimension of size 1 added at position `dim`.                                       |\n",
        "| [torch.permute(input, dims)](https://pytorch.org/docs/stable/generated/torch.permute.html)    | Returns a **view** of the original `input` with its dimensions permuted (rearranged) according to `dims`. |\n",
        "\n",
        "---\n",
        "\n",
        "## Why Use These Methods?\n",
        "\n",
        "Deep learning models (neural networks) rely heavily on manipulating tensors. Due to the rules of matrix multiplication and tensor operations, shape mismatches often cause errors. These methods help ensure that the right elements of your tensors align and mix correctly with elements of other tensors.\n",
        "\n",
        "For example:\n",
        "\n",
        "- **Reshaping** allows you to flatten or reorganize data to fit layer inputs.\n",
        "- **Viewing** provides a memory-efficient way to change tensor shape without copying data.\n",
        "- **Stacking** helps combine multiple tensors into a batch or along a new dimension.\n",
        "- **Squeezing/Unsqueezing** add or remove singleton dimensions to match expected input shapes.\n",
        "- **Permuting** rearranges tensor dimensions, which is useful for changing data layout (e.g., from channels-first to channels-last).\n",
        "\n",
        "---\n",
        "\n",
        "## Practical Example: Creating and Manipulating a Tensor\n",
        "\n",
        "Let's try these methods out by first creating a tensor and then applying some of these operations."
      ],
      "metadata": {
        "id": "LC8CQNpmH6nA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.arange(1, 8) # Create a tensor from numbers from 1 to 7\n",
        "print(X) # print the tensor\n",
        "print(X.shape) # print tensor's shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS5nq1QcIgDS",
        "outputId": "6577fd44-0146-4510-9163-db0867d8e895"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6, 7])\n",
            "torch.Size([7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Now let's add an extra dimension with `torch.reshape()`"
      ],
      "metadata": {
        "id": "ljBI_S3KI-d2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_reshaped = X.reshape(1, 7) # reshaping tensor X by adding dimension\n",
        "print(X_reshaped) # print the tensor\n",
        "print(X_reshaped.shape) # print the tensor's shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tDZ9AIJI4ts",
        "outputId": "a5968a03-ff7b-4288-dedd-e28d9993c546"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3, 4, 5, 6, 7]])\n",
            "torch.Size([1, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Now let's add an extra dimension with `torch.view()`"
      ],
      "metadata": {
        "id": "89e7Kwc0JvLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change view (keeps same data as original but changes view)\n",
        "# See more: https://stackoverflow.com/a/54507446/7900723\n",
        "\n",
        "Z = X.view(1, 7) # creating tensor z with copy of x then reshaping tensor z by adding dimension\n",
        "print(Z) # print the tensor\n",
        "print(Z.shape) # print the tensor's shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xWdDgGqJtpI",
        "outputId": "a1844a80-34ec-428c-933f-dc2d133e8565"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3, 4, 5, 6, 7]])\n",
            "torch.Size([1, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUT** Changing **values** of `Z` will changes **values** of `X` as well **BUT dimesions will remain**..\n",
        "\n",
        "Lets Try?"
      ],
      "metadata": {
        "id": "dy_0kqKKKucW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tensor `X` before changing tensor `Z`: {X}\") # print tensor `X` before changing `Z` tensor values..\n",
        "\n",
        "Z [:,0] = 5 # changing the first value of tensor `Z` to 5 instead of 1\n",
        "\n",
        "print(f\"Tensor `Z`: {Z}\") # print `Z` tensor after changing the first value\n",
        "print(f\"Tensor `X` after changing tensor `Z`: {X}\") # print `X` tensor and observe the first value, it changed to 5 also! :)\n",
        "\n",
        "# Don't Forget that only values change in view() NOT dimensions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi1S7o57Kx0F",
        "outputId": "c4daa66b-ff5f-4b03-953b-1d7e32a8aefe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor `X` before changing tensor `Z`: tensor([1, 2, 3, 4, 5, 6, 7])\n",
            "Tensor `Z`: tensor([[5, 2, 3, 4, 5, 6, 7]])\n",
            "Tensor `X` after changing tensor `Z`: tensor([5, 2, 3, 4, 5, 6, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we wanted to stack our new tensor on top of itself five times, we could do so with `torch.stack()` ."
      ],
      "metadata": {
        "id": "yRAeHuu_NC-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_stacked_rows = torch.stack([X, X, X], dim=0) # creating new tensor `X_stacked` containing `X` in rows >> NOTE: dim=0 stack in rows while dim=1 stack in columns\n",
        "X_stacked_columns = torch.stack([X, X, X], dim=1) # creating new tensor `X_stacked` containing `X` in columns\n",
        "\n",
        "print(X_stacked_rows)\n",
        "print(X_stacked_rows.shape)\n",
        "\n",
        "print('-'*50) # seperator\n",
        "\n",
        "print(X_stacked_columns)\n",
        "print(X_stacked_columns.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44HJo5lAM7gK",
        "outputId": "7f1aa39e-aa27-4e6f-9a9a-459b53486591"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 2, 3, 4, 5, 6, 7],\n",
            "        [5, 2, 3, 4, 5, 6, 7],\n",
            "        [5, 2, 3, 4, 5, 6, 7]])\n",
            "torch.Size([3, 7])\n",
            "--------------------------------------------------\n",
            "tensor([[5, 5, 5],\n",
            "        [2, 2, 2],\n",
            "        [3, 3, 3],\n",
            "        [4, 4, 4],\n",
            "        [5, 5, 5],\n",
            "        [6, 6, 6],\n",
            "        [7, 7, 7]])\n",
            "torch.Size([7, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about removing all single dimensions from a tensor?\n",
        "\n",
        "To do so you can use `torch.squeeze()`"
      ],
      "metadata": {
        "id": "nbRwVri8O3iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Previous tensor: {X_reshaped}\")\n",
        "print(f\"Previous shape: {X_reshaped.shape}\")\n",
        "\n",
        "# Remove extra dimension from x_reshaped\n",
        "X_squeezed = X_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {X_squeezed}\")\n",
        "print(f\"New shape: {X_squeezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZDvfjjSPODm",
        "outputId": "ace2cb7a-6e24-4698-d715-dac5d0b58e16"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([[5, 2, 3, 4, 5, 6, 7]])\n",
            "Previous shape: torch.Size([1, 7])\n",
            "\n",
            "New tensor: tensor([5, 2, 3, 4, 5, 6, 7])\n",
            "New shape: torch.Size([7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> **NOTE:**  this as squeezing the tensor to only have dimensions over 1."
      ],
      "metadata": {
        "id": "fWYSo78HP0ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Previous tensor: {X}\")\n",
        "print(f\"Previous shape: {X.shape}\")\n",
        "\n",
        "print('-'*50) # seperator\n",
        "\n",
        "X_wrong_squeezed = X.squeeze() # Remove extra dimension from `X` (`X` has only 1 dimension)\n",
        "print(f\"New tensor: {X_wrong_squeezed}\")\n",
        "print(f\"New shape: {X_wrong_squeezed.shape}\")\n",
        "\n",
        "print('\\nObservation? NOTHING CHANGED..Why? as we said before \"squeezing the tensor to only have dimensions over 1.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqhcWF4LP0NA",
        "outputId": "9a5327e0-6cb2-4735-f756-6fc819a201ad"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([5, 2, 3, 4, 5, 6, 7])\n",
            "Previous shape: torch.Size([7])\n",
            "--------------------------------------------------\n",
            "New tensor: tensor([5, 2, 3, 4, 5, 6, 7])\n",
            "New shape: torch.Size([7])\n",
            "\n",
            "Observation? NOTHING CHANGED..Why? as we said before \"squeezing the tensor to only have dimensions over 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And to do the reverse of `torch.squeeze()` you can use `torch.unsqueeze()` to add a dimension value of 1 at a specific inden"
      ],
      "metadata": {
        "id": "B3tcDB0aRlzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Previous tensor: {X_squeezed}\")\n",
        "print(f\"Previous shape: {X_squeezed.shape}\")\n",
        "\n",
        "# Add extra dimension to X_squeezed\n",
        "X_unsqueezed = X_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nNew tensor: {X_unsqueezed}\")\n",
        "print(f\"New shape: {X_unsqueezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45ihI-9hRvmS",
        "outputId": "728ea81f-6fc6-4f73-fdea-4b84a262ed4d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([5, 2, 3, 4, 5, 6, 7])\n",
            "Previous shape: torch.Size([7])\n",
            "\n",
            "New tensor: tensor([[5, 2, 3, 4, 5, 6, 7]])\n",
            "New shape: torch.Size([1, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also rearrange the order of axes values with `torch.permute(input, dims)`.\n",
        "Where the input gets turned into a `view` with new `dims` ."
      ],
      "metadata": {
        "id": "vSxKF_R7STcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensor with specific shape\n",
        "x_original = torch.rand(size=(224, 224, 3))\n",
        "\n",
        "# Permute the original tensor to rearrange the axis order\n",
        "x_permuted = x_original.permute(2, 0, 1)  # shifts axis ( 0 -> 1, 1 -> 2, 2 -> 0 ) .... in other words (2, 0, 1) are indexs of `x_original` tensor\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTgtBDcZSyQV",
        "outputId": "1bc9f598-73f8-4c9c-b3e3-bd692919da5f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Thanks! Don't forget to Star the repo 🫡⭐**"
      ],
      "metadata": {
        "id": "DPRDr9DfH2qB"
      }
    }
  ]
}
